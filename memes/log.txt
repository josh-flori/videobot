###############
#     4/20    #
###############
Got connection to reddit/google back up and running
Images pulling from reddit fine
Began writing text cleaning algo, includes 1 simple regex
Wrote function to get size of text boxes relative to entire image as an attempt to remove any extra small text, but
somehow the results on the first image were not useful regardless of whether i considered area of bounding boxes or height
only. I think I should give up on that... a better approach would be with each video to export list of timestamps on each
section and allow user to re-run removing any objectionable timestamped sections.

I feel the images are cleaner this time anyway.

I've reviewed a number of text outputs and they look g2g with 0 processing. Tomorrow I will work on getting audio and
bounding boxes/rectangles.
I've thought about it and I think training a network to recognize where to put the bounding boxes would be good. There
are enough general cases I think it should be ok enough of the time. Try this first:
https://blog.insightdatascience.com/how-to-train-your-own-yolov3-detector-from-scratch-224d10e55de2

frames to potentially remove: 119,129,13,133,145,18,184
161 wouldn't load

###############
#     4/22    #
###############
I'm changing my thoughts.. i feel it would be better to just use the bounding boxes from the text recognition to block
out the text. you need to implement a lot of logic but i think it will work better. then just use the network for
recognizing frames although to be honest you may be able to do it without the network... idk about that right now.


I tested using paragraph blocks to create text and it looks promising enough. Moving onto masking out sections of the
paragraph if ':' contained within.

###############
#     4/23    #
###############
it's working reasonably well... need to figure out:
how to clean text in this format
how to force proper text order
if i need to uncover text at all in certain panel types... maybe in 4 panel types just ignore text blocks entirely...
    maybe you could just have the network recognize 4 panels and then split it evenly into 4 quadrants

im trying to think of how to remove bad text... the actual text IS included as a single object...
if i could convert this to something iterable it might be easier?

ok figured that shit out fast enough...

NEXT UP! break up any multi-line paragraph into individual blocks

###############
#     4/24    #
###############
trying to break up multi-lines... i think you could just count the number of '/n's.... and then just divide the
height of the paragraph by that number and create that many blocks, assuming they are all the same height of course....

DONE.

###############
#     4/26    #
###############
used google automl to create a pretty decent network. time to start writing code for it!

so how would we solve this problem? lets map out some if statements....
if annotation_count==1 & cleanified(x,x)==[0,1] & cleanified(y)>.05
well... in order to reveal any frame you HAVE to know it's relationship to the text
you could have a like, "which_comes_next()" function which just has access to all the bounding boxes for text and frames
and then just is like, well, which type comes next? and then that would be like the master function creating all the boxes...

I made a successful function for creating boxes/frames/text whatever at least for image 0! moving on to the next...


ok debugged some shitty code... next step would be to write function to trim boxes down to the intersection of mostly
white and mostly non-white pixels like in the case of image 4.jpg.

welp, I guess pretty much have a good thing going here :D works pretty damn well
You know what to do from here... just wrap it up and make sure nothing weird pops up. :D

###############
#     4/27    #
###############
need to work on getting aws config figured out to run audio.. then run audio...
yadayada... too tired to continue... but still happy with my progress.